{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e1473-0ada-4180-83ee-1d35dd910a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "1>import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_urls(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        video_urls = []\n",
    "\n",
    "        for video in soup.find_all('video', limit=5):\n",
    "            source_tag = video.find('source')\n",
    "            if source_tag and 'src' in source_tag.attrs:\n",
    "                video_url = source_tag['src']\n",
    "                video_urls.append(video_url)\n",
    "\n",
    "        return video_urls\n",
    "    else:\n",
    "        print(\"Error: Failed to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace 'YOUR_URL_HERE' with the URL of the webpage containing the videos.\n",
    "    url = 'YOUR_URL_HERE'\n",
    "    video_urls = extract_video_urls(url)\n",
    "\n",
    "    if video_urls:\n",
    "        print(\"Video URLs:\")\n",
    "        for i, video_url in enumerate(video_urls, start=1):\n",
    "            print(f\"{i}. {video_url}\")\n",
    "    else:\n",
    "        print(\"No video URLs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab2359-bec7-403c-a379-bba5142f0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "2>.import os\n",
    "import googleapiclient.discovery\n",
    "\n",
    "# Set your API key here. Make sure you have enabled the YouTube Data API v3 in your Google Cloud Console.\n",
    "API_KEY = \"YOUR_YOUTUBE_API_KEY\"\n",
    "\n",
    "def extract_video_thumbnails(channel_id):\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)\n",
    "\n",
    "    # Fetch the first five videos from the channel\n",
    "    request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        channelId=channel_id,\n",
    "        type=\"video\",\n",
    "        maxResults=5\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    video_thumbnails = []\n",
    "    for item in response[\"items\"]:\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        video_thumbnail = f\"https://i.ytimg.com/vi/{video_id}/maxresdefault.jpg\"\n",
    "        video_thumbnails.append(video_thumbnail)\n",
    "\n",
    "    return video_thumbnails\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'YOUR_CHANNEL_ID_HERE' with the YouTube channel ID or playlist ID from which you want to extract video thumbnails.\n",
    "    channel_id = \"YOUR_CHANNEL_ID_HERE\"\n",
    "    video_thumbnails = extract_video_thumbnails(channel_id)\n",
    "\n",
    "    if video_thumbnails:\n",
    "        print(\"Video Thumbnails:\")\n",
    "        for i, thumbnail_url in enumerate(video_thumbnails, start=1):\n",
    "            print(f\"{i}. {thumbnail_url}\")\n",
    "    else:\n",
    "        print(\"No video thumbnails found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a0b57-df89-4a8c-a3d3-a2df1323a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "3>import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_titles(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        video_titles = []\n",
    "\n",
    "        for thumbnail in soup.select('a#thumbnail'):\n",
    "            title = thumbnail.get('title')\n",
    "            if title:\n",
    "                video_titles.append(title)\n",
    "\n",
    "        return video_titles[:5]\n",
    "    else:\n",
    "        print(\"Error: Failed to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace 'YOUR_URL_HERE' with the URL of the YouTube channel page.\n",
    "    url = 'YOUR_URL_HERE'\n",
    "    video_titles = extract_video_titles(url)\n",
    "\n",
    "    if video_titles:\n",
    "        print(\"Video Titles:\")\n",
    "        for i, title in enumerate(video_titles, start=1):\n",
    "            print(f\"{i}. {title}\")\n",
    "    else:\n",
    "        print(\"No video titles found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c6027-3197-48f9-a060-4d3928ea2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "4>import requests\n",
    "import cv2\n",
    "import pytesseract\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_thumbnail_urls(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        thumbnail_urls = []\n",
    "\n",
    "        for video in soup.find_all('a', class_='yt-simple-endpoint inline-block style-scope ytd-thumbnail', limit=5):\n",
    "            thumbnail_url = video.find('img')['src']\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "        return thumbnail_urls\n",
    "    else:\n",
    "        print(\"Error: Failed to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "def extract_views_from_thumbnails(thumbnail_urls):\n",
    "    views_list = []\n",
    "\n",
    "    for url in thumbnail_urls:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            image_array = bytearray(response.content)\n",
    "            image = cv2.imdecode(image_array, cv2.IMREAD_GRAYSCALE)\n",
    "            text = pytesseract.image_to_string(image)\n",
    "            views = ''.join(filter(str.isdigit, text))\n",
    "            views_list.append(views)\n",
    "\n",
    "    return views_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace 'YOUR_URL_HERE' with the URL of the YouTube page containing the videos.\n",
    "    url = 'YOUR_URL_HERE'\n",
    "    thumbnail_urls = get_thumbnail_urls(url)\n",
    "\n",
    "    if thumbnail_urls:\n",
    "        views_list = extract_views_from_thumbnails(thumbnail_urls)\n",
    "\n",
    "        print(\"Number of Views:\")\n",
    "        for i, views in enumerate(views_list, start=1):\n",
    "            print(f\"{i}. {views}\")\n",
    "    else:\n",
    "        print(\"No thumbnail URLs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecdc0f-c9e8-43d9-99d4-4e5e8380434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8576b3-2853-471c-94e3-97e399af4e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb847b5d-6c04-4cde-99bf-e49cc6c383b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
